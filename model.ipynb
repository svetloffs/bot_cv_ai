{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/fungi/train_images_cat.txt', 'r') as f:\n",
    "    train_images_cat = f.readlines()\n",
    "f.close()\n",
    "with open('./dataset/fungi/val_images_cat.txt', 'r') as f:\n",
    "    val_images_cat = f.readlines()\n",
    "f.close()\n",
    "len(train_images_cat), len(val_images_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_total = [i.split('@:@')[1].strip().strip('\\n') for i in train_images_cat]\n",
    "train_cats_total = [i.split('@:@')[0].strip().strip('\\n') for i in train_images_cat]\n",
    "train_images_total[0], train_cats_total[0]\n",
    "# train_images = [\n",
    "#     \"./dataset/fungi/train/images/\" + i.split('@:@')[-1].strip('\\n') for i in train_images_cat\n",
    "# ]\n",
    "train_images = [str(i) for i in pathlib.Path('./dataset/fungi/train/').glob('**/*.JPG')]\n",
    "# train_images[:3]\n",
    "train_lbls = [\n",
    "    i.split('@:@')[0].strip('\\n') for i in train_images_cat\n",
    "]\n",
    "# train_lbls[:3]\n",
    "len(train_images), len(train_lbls)\n",
    "# train_images_names[:3]\n",
    "train_images_names = [\"/\".join(str(i).split('/')[-2:]) for i in pathlib.Path('./dataset/fungi/train/').glob('**/*.JPG')]\n",
    "train_images_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame([train_images_total, train_cats_total]).T\n",
    "df_full.columns = ['file_name', 'label']\n",
    "# df_full.head()\n",
    "df_train = pd.DataFrame([train_images, train_lbls[:len(train_images)]]).T\n",
    "df_train.columns = ['file_path', 'label']\n",
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_train['file_name'] = df_train['file_path'].apply(lambda x: \"/\".join(x.split('/')[-2:]))\n",
    "# df_train.head()\n",
    "df_train_real = pd.merge(left=df_full, right=df_train, on = 'file_name', how='inner')\n",
    "df_train_real.drop(columns=['label_y'], inplace=True)\n",
    "df_train_real['file_name'] = df_train_real['file_name'].apply(lambda x: x.split('/')[-1])\n",
    "df_train_real.columns = ['file_name', 'label', 'file_path']\n",
    "df_train_real['label_name'] = df_train_real['file_path'].apply(lambda x: x.split('/')[-2])\n",
    "df_train_real['label'] = df_train_real['label'].astype(int)\n",
    "df_train_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_total = [i.split('@:@')[1].strip().strip('\\n') for i in val_images_cat]\n",
    "val_cats_total = [i.split('@:@')[0].strip().strip('\\n') for i in val_images_cat]\n",
    "# val_images_total[0], train_cats_total[0]\n",
    "val_images = [str(i) for i in pathlib.Path('./dataset/fungi/val/').glob('**/*.JPG')]\n",
    "val_lbls = [i.split('@:@')[0].strip('\\n') for i in train_images_cat]\n",
    "val_images_names = [\"/\".join(str(i).split('/')[-2:]) for i in pathlib.Path('./dataset/fungi/val/').glob('**/*.JPG')]\n",
    "len(val_images), len(val_lbls), val_images_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame([val_images_total, val_cats_total]).T\n",
    "df_full.columns = ['file_name', 'label']\n",
    "# df_full.head()\n",
    "df_val = pd.DataFrame([val_images, val_lbls[:len(val_images)]]).T\n",
    "df_val.columns = ['file_path', 'label']\n",
    "df_val['label'] = df_val['label'].astype(int)\n",
    "df_val['file_name'] = df_val['file_path'].apply(lambda x: \"/\".join(x.split('/')[-2:]))\n",
    "df_val_real = pd.merge(left=df_full, right=df_val, on = 'file_name', how='inner')\n",
    "df_val_real.drop(columns=['label_y'], inplace=True)\n",
    "df_val_real['file_name'] = df_val_real['file_name'].apply(lambda x: x.split('/')[-1])\n",
    "df_val_real.columns = ['file_name', 'label', 'file_path']\n",
    "df_val_real['label_name'] = df_val_real['file_path'].apply(lambda x: x.split('/')[-2])\n",
    "df_val_real['label'] = df_val_real['label'].astype(int)\n",
    "df_val_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train, df_val, df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(df_train_real.iloc[0,2]),);\n",
    "# plt.legend(show=True)\n",
    "plt.title(label=f\"{str(df_train_real.iloc[0, 1])}/{str(df_train_real.iloc[0, -1])}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_real[df_val_real['label']==650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(df_val_real.iloc[0,2]),);\n",
    "# plt.legend(show=True)\n",
    "plt.title(label=str(df_val_real.iloc[0, 1]) + str(df_val_real.iloc[0, -1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# # os.makedirs(\"./dataset/fungi/val\", exist_ok=True)\n",
    "# for src in tqdm(train_images[:]):\n",
    "#     os.makedirs(\"/\".join(src.replace('fungi_train_val/images', 'train').split('/')[:-1]), exist_ok=True)\n",
    "#     shutil.copyfile(src, src.replace('fungi_train_val/images', 'train'))\n",
    "# import shutil\n",
    "# import os\n",
    "# # os.makedirs(\"./dataset/fungi/val\", exist_ok=True)\n",
    "# for src in tqdm(val_images[:]):\n",
    "#     os.makedirs(\"/\".join(src.replace('fungi_train_val/images', 'val').split('/')[:-1]), exist_ok=True)\n",
    "#     shutil.copyfile(src, src.replace('fungi_train_val/images', 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.RandomRotation(degrees=(30, 70)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "# the validation transforms\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "ROOT = \"./dataset/fungi\"\n",
    "# training dataset\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root= f'{ROOT}/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "# validation dataset\n",
    "valid_dataset = datasets.ImageFolder(\n",
    "    root= f'{ROOT}/val',\n",
    "    transform=valid_transform\n",
    ")\n",
    "# training data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers = 4, \n",
    "    pin_memory=True\n",
    ")\n",
    "# validation data loaders\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers = 2, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(df_train_real['label'].unique().tolist())\n",
    "len(classes), classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_real[df_train_real['label']==26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5}' for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to save the trained model to disk.\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, 'outputs/model.pth')\n",
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    # accuracy plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_acc, color='green', linestyle='-', \n",
    "        label='train accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_acc, color='blue', linestyle='-', \n",
    "        label='validataion accuracy'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('outputs/accuracy.png')\n",
    "    \n",
    "    # loss plots\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('outputs/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# net = Net()\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 5)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(256, 50)\n",
    "        self.fc1 = nn.Linear(256, 341)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "# for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 2\n",
    "# device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(f\"Computation device: {device}\\n\")\n",
    "model = CNNModel().to(device)\n",
    "print(model)\n",
    "# total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_DEVICE_AVAILABLE'] = '0'\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "t = torch.tensor([1,2], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        print(outputs.shape)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc\n",
    "# validation\n",
    "def validate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            outputs = model(image)\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.classes), train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []\n",
    "# start the training\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_loader, \n",
    "                                              optimizer, criterion)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(model, valid_loader,  \n",
    "                                                 criterion)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "    print('-'*50)\n",
    "    # time.sleep(5)\n",
    "    \n",
    "# save the trained model weights\n",
    "# save_model(epochs, model, optimizer, criterion)\n",
    "# save the loss and accuracy plots\n",
    "# save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
    "print('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((3,10), device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
