{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install pandas\n",
    "# !pip install sweetviz\n",
    "# !pip install ydata-profiling\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sweetviz\n",
    "# sweetviz.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import tensorflow as tf\n",
    "import json\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "# from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    f.close()\n",
    "    # Create different lists from the data dictionary\n",
    "\n",
    "    annotations = pd.DataFrame(data[\"annotations\"])\n",
    "    category = pd.DataFrame(data[\"categories\"])\n",
    "    info = pd.DataFrame.from_dict(data[\"info\"], orient='index')\n",
    "    images = pd.DataFrame(data['images'])\n",
    "    licenses = pd.DataFrame(data['licenses'])\n",
    "    return annotations, category, info, images, licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train_path = './dataset/fungi/train_val_annotations/train.json'\n",
    "json_val_path = './dataset/fungi/train_val_annotations/val.json'\n",
    "tr_annotation, tr_category, tr_info, tr_images, tr_licenses = read_json(json_train_path)\n",
    "val_annotation, val_category, val_info, val_images, val_licenses = read_json(json_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_annotation['category_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted([int(i) for i in tr_annotation['category_id'].unique().tolist()])\n",
    "categories[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_json_df(images, annotations, category):\n",
    "    \"\"\" args = takes the three important dataframes\n",
    "    returns = create a merged dataframe with all the important data\n",
    "    \"\"\"\n",
    "    data_df = images.copy()\n",
    "\n",
    "    ## to the images dataframe, we add the category_id column - our target\n",
    "    data_df['category_id'] = annotations[annotations['image_id'] == data_df['id']]['category_id']\n",
    "    category.set_index('id')\n",
    "    data_df = pd.merge(left=data_df, right=category, how='left', left_on='category_id', right_on='id')\n",
    "    data_df.drop(columns = ['id_y'], inplace=True)\n",
    "    #change the column to a string?\n",
    "    data_df['category_id'] = data_df['category_id'].astype(str) \n",
    "    # Add the columns of image name and its subdirectory/catefory\n",
    "    data_df['image_name'] = data_df['file_name'].str.split('/').str[2]\n",
    "    data_df['subdir'] = data_df['file_name'].str.split(pat='/', n=1).str[1]\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = create_merged_json_df(tr_images, tr_annotation, tr_category)\n",
    "tr_data['freq'] = tr_data.groupby('category_id')['category_id'].transform('count')\n",
    "# tr_data['category_id'] = tr_annotation[tr_annotation['image_id'] == tr_data['id']]['category_id']\n",
    "# tr_data.sort_values(by=['file_name'], inplace=True)\n",
    "tr_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data[tr_data['category_id']=='650'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_train = sorted([int(i) for i in tr_data['category_id'].unique().tolist()])\n",
    "category_id_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = create_merged_json_df(val_images, val_annotation, val_category)\n",
    "val_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_category.set_index('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_report = sv.analyze(tr_images)\n",
    "# #display the report\n",
    "# images_report.show_html('sweetviz_train_images.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_report = sv.analyze(tr_data)\n",
    "# #display the report\n",
    "# train_data_report.show_html('sweetviz_train_data.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "# profile = ProfileReport(tr_images, title='images Pandas Profiling Report')\n",
    "# # profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile.to_file('Report_train_json.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_names = tr_data['file_name'].to_list()\n",
    "val_images_names = val_data['file_name'].to_list()\n",
    "len(train_images_names), len(val_images_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_cat = tr_data['category_id'].to_list()\n",
    "val_images_cat = val_data['category_id'].to_list()\n",
    "len(train_images_cat), len(val_images_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key_value_lst = [[key, value] for key, value in zip(train_images_cat, train_images_names)]\n",
    "val_key_value_lst = [[key, value] for key, value in zip(val_images_cat, val_images_names)]\n",
    "train_key_value_lst[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key_value_lst[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_key_value_lst[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_key_value_lst[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/fungi/train_images_cat.txt', 'w') as f:\n",
    "    for line in train_key_value_lst:\n",
    "        f.write(f\"{line[0]}@:@\" + \"/\".join(line[1].split('/')[1:]) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/fungi/val_images_cat.txt', 'w') as f:\n",
    "    for line in val_key_value_lst:\n",
    "        f.write(f\"{line[0]}@:@\" + \"/\".join(line[1].split('/')[1:]) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/fungi/val_images.txt', 'w') as f:\n",
    "    for line in val_images_names:\n",
    "        f.write(\"/\".join(line.split('/')[1:]) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
